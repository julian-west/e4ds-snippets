{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16461af8",
   "metadata": {},
   "source": [
    "# ML Design Pattern: Repeatable Splitting\n",
    "\n",
    "\n",
    "## Reproducible ML: Maybe you shouldn't be using train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa138163",
   "metadata": {},
   "source": [
    "Reproducibility is critical for robust data science -- after all, it is a science.\n",
    "\n",
    "But reproducibility in ML can be surprisingly difficult. \n",
    "\n",
    "The behaviour of your model doesn't only depend on your code, but also the underlying dataset that was used to train it.\n",
    "\n",
    "Therefore, you need to keep tight control on the version of the dataset that was used for training any particular model.\n",
    "\n",
    "A fundamental tenet of the ML workflow is splitting your data into training and testing sets. This helps evaluate the performance of your model on unseen data.\n",
    "\n",
    "It is vitally important to be able to reproducibly split your data so you can effectively compare the performance of different model candidates, troubleshoot performance issues and  for colleagues to obtain the same results.\n",
    "\n",
    "How you split your data can have a big effect on the end model performance and success of the model.\n",
    "\n",
    "The common way to split your data is to use Sklearn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.\n",
    "\n",
    "Out of the box, the `train_test_split` function will randomly split your data. Each time you run the function you will get a different train and test split for your data. Not ideal for reproducibility.\n",
    "\n",
    "\"Ah!\" you say. \"I set the random seed so it is reproducible!\". \n",
    "\n",
    "Fair point. Setting random seeds is an excellent idea and goes a long way to improve reproducibility and I would highly recommend setting random seeds for any functions which have probabilistic outputs. \n",
    "\n",
    "However, random seeds might not be enough to ensure reproducibility. In this post I will explain why the `train_test_split` with random seed does not always guarantee reproducibility and *transparency*.\n",
    "\n",
    "\n",
    "<!-- ML is experimental and iterative, you need to be able to keep as many variables constant as possible. That includes which datapoints are used for training and which are used for testing. -->\n",
    "\n",
    "<!-- - The crux, why is this important?: For reproducibility you want to ensure the data that was used to train a model remains consistent when you go to retrain it. This helps comparison of performance and debugging.\n",
    "- Particularly if you need to retrain your model in the future (i.e. it is not just a one off). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72889ace",
   "metadata": {},
   "source": [
    "## What is the problem with train_test_split?\n",
    "\n",
    "**Setting the random reed only guarantees reproducible splits if the underlying data does not change when retraining the model.**\n",
    "\n",
    "The splits are sensitive to the *ordering* of the data. If your dataset is shuffled or amended in any way (e.g. new data is added), the data will be split differently. This means datapoints that were in the original training set might now end up in the test set and visa versa.\n",
    "\n",
    "Therefore, for the same dataset you can get different splits depending on how the rows in the dataset are ordered. This is not a very robust solution. Even if one datapoint is removed in the future or if the order of two rows are switched, you will get a completely different training and test split.\n",
    "\n",
    "Let's demonstrate the issue with a simple demo.\n",
    "\n",
    "We will first download an example dataset from skelearn.datasets and create an 'index' column to uniquely identify each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006cad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13c8945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0      0        17.99         10.38          122.80     1001.0   \n",
       "1      1        20.57         17.77          132.90     1326.0   \n",
       "2      2        19.69         21.25          130.00     1203.0   \n",
       "3      3        11.42         20.38           77.58      386.1   \n",
       "4      4        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   mean symmetry  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"from sklearn.datasets import load_breast_cancer\\n\\nimport pandas as pd\\n\\n# download an example dataset\\ndata = load_breast_cancer()\\ndf = pd.DataFrame(data[\\\"data\\\"], columns=data[\\\"feature_names\\\"])\\n\\n# create an 'index' column to use to uniquely identify each row\\ndf = df.reset_index(drop=False)\\n\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"from sklearn.datasets import load_breast_cancer\\n\\nimport pandas as pd\\n\\n# download an example dataset\\ndata = load_breast_cancer()\\ndf = pd.DataFrame(data[\\\"data\\\"], columns=data[\\\"feature_names\\\"])\\n\\n# create an 'index' column to use to uniquely identify each row\\ndf = df.reset_index(drop=False)\\n\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# download an example dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "\n",
    "# create an 'index' column to use to uniquely identify each row\n",
    "df = df.reset_index(drop=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2c124",
   "metadata": {},
   "source": [
    "Now let's split the data using Sklearn's `train_test_split` and then shuffle the dataframe and split the data again. We will set also the random state (seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1224c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import train_test_split\\n\\n# set parameters\\nTEST_RATIO = 0.1\\nSEED = 42\\n\\n# split into training and test using a random seed\\nx_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\\n\\n# shuffle the orginal dataframe\\ndf_shuffled = df.sample(frac=1)\\n\\n# split the shuffled dataframe using the same random seed\\nx_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\\n    df_shuffled, test_size=TEST_RATIO, random_state=SEED\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import train_test_split\\n\\n# set parameters\\nTEST_RATIO = 0.1\\nSEED = 42\\n\\n# split into training and test using a random seed\\nx_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\\n\\n# shuffle the orginal dataframe\\ndf_shuffled = df.sample(frac=1)\\n\\n# split the shuffled dataframe using the same random seed\\nx_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\\n    df_shuffled, test_size=TEST_RATIO, random_state=SEED\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set parameters\n",
    "TEST_RATIO = 0.1\n",
    "SEED = 42\n",
    "\n",
    "# split into training and test using a random seed\n",
    "x_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\n",
    "\n",
    "# shuffle the orginal dataframe\n",
    "df_shuffled = df.sample(frac=1)\n",
    "\n",
    "# split the shuffled dataframe using the same random seed\n",
    "x_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\n",
    "    df_shuffled, test_size=TEST_RATIO, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329cab57",
   "metadata": {},
   "source": [
    "Ideally the rows contained in the `x_test_skl` and `x_test_skl_shuffled` test sets should be identical. \n",
    "\n",
    "However, when we compare the row ids in each set they are different even though the random state (seed) was the same both times. Nothing in the data has changed, we have just shuffled the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f860ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# compare the row ids included in each test set.\\n# should return True\\nset(x_test_skl[\\\"index\\\"]) == set(x_test_skl_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_formatted_code = \"# compare the row ids included in each test set.\\n# should return True\\nset(x_test_skl[\\\"index\\\"]) == set(x_test_skl_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the row ids included in each test set.\n",
    "# should return True\n",
    "set(x_test_skl[\"index\"]) == set(x_test_skl_shuffled[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f4e6e",
   "metadata": {},
   "source": [
    "This highlights just how sensitive the `train_test_split` function is, even to ordering of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4c5c4",
   "metadata": {},
   "source": [
    "## What are the consequences of using random seed when retraining the model with updated data?\n",
    "\n",
    "The results of your model can vary significantly depending on how the data was split.\n",
    "\n",
    "**If you don't have full control of the dataset, you cannot guarantee reproducibility**\n",
    "\n",
    "It could be risky.\n",
    "\n",
    "Can you be sure the dataset has not changed between training runs?\n",
    "\n",
    "For example, if a colleague has removed an outlier data point or if new rows have been added. Your data splits will be completely different to your original splits.\n",
    "\n",
    "You can use data versioning tools to help keep track of changes, however, that doesn't prevent your data splits changing. It would be better to protect against split changes in your code.\n",
    "\n",
    "\n",
    "**Difficult to effectively compare models**\n",
    "\n",
    "When comparing models we what to be able to control as many variables as possible. That should include which datapoints were used for training and testing.\n",
    "\n",
    "Ideally when you split your data, the training and test data should follow the same data distributions and properties. However, there will inevitably be some statistical variation. \n",
    "\n",
    "If you data splits are significantly different between runs you might observe considerable differences in performance. For example if you have a couple of outliers which were in your training set for the original training run, but are now in your test set, you model performance might 'decline' as it could not predict outlier values in the test set as well as before.\n",
    "\n",
    "**Difficult to debug**\n",
    "\n",
    "Imagine you add some new data points to your dataset and retrain your model, but the performance of the model drops.\n",
    "\n",
    "If you have used `train_test_split` you will have different splits. It would be difficult to understand whether the new data made the model worse, or, as highlighted in the previous point, it was just because the data was split differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f8bd6",
   "metadata": {},
   "source": [
    "## When might train_test_split not be appropriate?\n",
    "\n",
    "**If you need to retrain your model with original + new data**\n",
    "\n",
    "Adding new data to your existing data set will cause completely different splits. Your original data splits will not be reproducible.\n",
    "\n",
    "If you are retraining the model with completely new data it isn't a problem as obviously all the training and test datapoints will be different.\n",
    "\n",
    "\n",
    "**If you are retrieving your source data from an evolving data source**\n",
    "\n",
    "For example a table in BigQuery which has new rows appended to it, or if you are working with filepaths as the input (e.g. images) and new images are being added to your source folder.\n",
    "\n",
    "Or you cannot guarantee the order of the rows.\n",
    "\n",
    "**You want to be able to reproducibly sample from the source dataset.**\n",
    "\n",
    "\n",
    "**If there is a possibility of data leakage**\n",
    "\n",
    "- which means certain cross-sections should *only* be in the training set or *only* in the test set\n",
    "  - for example airline delays dataset\n",
    "  \n",
    "  \n",
    "**If you have large datasets which do not fit in memory**\n",
    "\n",
    "\n",
    "\n",
    "**If your production code will be rewritten in another language**\n",
    "  - e.g. if using BQML or if your dataset moves location from csv to BigQuery table in the future\n",
    "  - also if you are experimenting comparing a service like BQML to your custom Python model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce2b57",
   "metadata": {},
   "source": [
    "## The Solution: Hashing\n",
    "\n",
    "### What is hashing?\n",
    "\n",
    "### Reasons to use hashing\n",
    "\n",
    "**Improves development**\n",
    "\n",
    "Working with colleagues in parallel on models\n",
    "\n",
    "**Consistent splitting across raw and preprocessed data**\n",
    "\n",
    "Can help with experimentation if you can ensure the same splits across different preprocessed datasets.\n",
    "\n",
    "\n",
    "### How does it work for splitting data?\n",
    "\n",
    "use unique id for the row and convert to an integer\n",
    "split into buckets using modulus operation\n",
    "select all values less than arbitrary value\n",
    "\n",
    "### Farmhash\n",
    "\n",
    "there are many hashing algorithms. example in sklearn, however, farmhash is another alternative which is easy to use and also supported (recommended) by BigQuery\n",
    "\n",
    "we want lightweight...go through characteristics we want\n",
    "\n",
    "why use fingerprint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a74469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13009744463427800296\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# FARMHASH SIMPLE DEMO\\n# show single value hashing results\\n\\nimport farmhash\\n\\nhashed_value = farmhash.fingerprint64(\\\"hello\\\")\\nprint(hashed_value)\";\n",
       "                var nbb_formatted_code = \"# FARMHASH SIMPLE DEMO\\n# show single value hashing results\\n\\nimport farmhash\\n\\nhashed_value = farmhash.fingerprint64(\\\"hello\\\")\\nprint(hashed_value)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FARMHASH SIMPLE DEMO\n",
    "# show single value hashing results\n",
    "\n",
    "import farmhash\n",
    "\n",
    "hashed_value = farmhash.fingerprint64(\"hello\")\n",
    "print(hashed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1aba99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# assign a bucket using the modulus operation\\nhashed_value % 10\";\n",
       "                var nbb_formatted_code = \"# assign a bucket using the modulus operation\\nhashed_value % 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assign a bucket using the modulus operation\n",
    "hashed_value % 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f7596",
   "metadata": {},
   "source": [
    "Therefore, our \"hello\" value would be assigned to bucket 6 of 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f6cba",
   "metadata": {},
   "source": [
    "## Splitting the data using Farmhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61642fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# DEMO\\n# show distribution\";\n",
       "                var nbb_formatted_code = \"# DEMO\\n# show distribution\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEMO\n",
    "# show distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26040d8d",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "\n",
    "- Will not produce exactly 10% of the dataset --> less of a problem for large datasets\n",
    "- Which column should you use to hash?\n",
    "- How many buckets to chose?\n",
    "\n",
    "\n",
    "**Platform cross-compatibility quirks**\n",
    "\n",
    "Having said that hashing is consistent across platforms. That is true to an extent.\n",
    "\n",
    "While researching for this article, I tested to see if the dataset splits from my Python program were identical to a dataset stored in [BigQuery using SQL instead](https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39).\n",
    "\n",
    "To my surprise, I found some edge cases where the results differed.\n",
    "\n",
    "After a lot of head scratching, I came across a two quirks of BigQuery which were causing the issue:\n",
    "1. [BigQuery does not support unsigned integers](https://stackoverflow.com/questions/51892989/how-does-bigquerys-farm-fingerprint-represent-a-64-bit-unsigned-int)\n",
    "2. BigQuery, [C and C++ have different implementations for the modulus operation](https://stackoverflow.com/questions/3883004/the-modulo-operation-on-negative-numbers-in-python) compared to Python when it comes to negative numbers\n",
    "\n",
    "The `farmhash.fingerprint64` method returns an *[unsigned](https://stackoverflow.com/questions/247873/signed-versus-unsigned-integers)* integer. Whereas the BigQuery `FARM_FINGERPRINT` function returns an `INT64` datatype. Therefore, BigQuery converts the farmhash output to a *signed* integer. The value of signed integer might be different to the original unsigned integer value and it might be negative.\n",
    "\n",
    "Ok, can't we just convert our Python farmhash value to a signed integer?\n",
    "\n",
    "Well, this leads to the second problem. In order to split the data into different buckets, we used the modulus operation. [Python and C (and BigQuery) have different implementations of the modulus operator](https://stackoverflow.com/questions/1907565/c-and-python-different-behaviour-of-the-modulo-operation#:~:text=Both%20variants%20are%20correct%2C%20however,same%20result%20as%20in%20Python.) which affects the results for negative numbers.\n",
    "\n",
    "Therefore, if our signed integer is negative, the bucket it is assigned will differ depending on if we calculated it using Python's modulus operator (`%`) or BigQuery's `MOD` function. \n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "# in python\n",
    "-1%10 = 9\n",
    "\n",
    "# in BigQuery\n",
    "MOD(-1,10) = -1\n",
    "```\n",
    "\n",
    "Does this mean hashing is not platform independent? \n",
    "\n",
    "Well, not really, just that you need to check how unsigned integers are treated and the how modulus of negative numbers is implemented.\n",
    "\n",
    "We can fix our Python implementation to protect against these issues by converting the unsigned output of farmhash to a signed int and using a custom 'C-like' implementation of the modulus function.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def signed_hash_value(value:Any) -> int:\n",
    "    \"\"\"Convert unsigned hashed value to a signed int\"\"\"\n",
    "    hashed_value = farmhash.fingerprint64(str(value))\n",
    "    return np.uint64(hashed_value).astype(\"int64\")\n",
    "    \n",
    "def c_mod(a:int, b:int)->int:\n",
    "    \"\"\"Modulus function implemented to behave like 'C' languages\"\"\"\n",
    "    res = a % b\n",
    "    if a < 0:\n",
    "        res -= b\n",
    "    return res\n",
    "\n",
    "# this will give the same results in Python and BigQuery (and C-languages)\n",
    "assigned_bucket = abs(c_mod(signed_hash_value,10))\n",
    "```\n",
    "\n",
    "[Note: the order of the abs and mod functions is important](https://mentin.medium.com/be-careful-with-abs-function-8e91c78715d5)\n",
    "\n",
    "https://stackoverflow.com/questions/63341637/python-vs-bigquery-farmhash-sometimes-do-not-equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9615921",
   "metadata": {},
   "source": [
    "### Alternatives to hashing\n",
    "\n",
    "train test split, but could also create an additional column and explicitly assign a split (see Abishek Thakur - I remember that he like to do this). However, that creates an extra column of storage which takes up additional space and could be prone to someone changing it and it wouldn't be determininstic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8d817",
   "metadata": {},
   "source": [
    "### Other use cases for hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba1533",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60f1b8",
   "metadata": {},
   "source": [
    "## References and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce4668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017fc683",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00768709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2818e956",
   "metadata": {},
   "source": [
    "### More indepth code on BigQuery unsigned int debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15253d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbd333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0      0        17.99         10.38          122.80     1001.0   \n",
       "1      1        20.57         17.77          132.90     1326.0   \n",
       "2      2        19.69         21.25          130.00     1203.0   \n",
       "3      3        11.42         20.38           77.58      386.1   \n",
       "4      4        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   mean symmetry  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from typing import Any\\n\\nimport farmhash\\nimport seaborn as sns\\nfrom sklearn.datasets import load_breast_cancer\\n\\nimport pandas as pd\\n\\n# set parameters\\nTEST_RATIO = 0.1\\nSEED = 42\\nBUCKETS = 10\\n\\n# download an example dataset\\ndata = load_breast_cancer()\\ndf = pd.DataFrame(data[\\\"data\\\"], columns=data[\\\"feature_names\\\"])\\n\\n# create an 'index' column to use to uniquely identify each row\\ndf = df.reset_index(drop=False)\\n\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"from typing import Any\\n\\nimport farmhash\\nimport seaborn as sns\\nfrom sklearn.datasets import load_breast_cancer\\n\\nimport pandas as pd\\n\\n# set parameters\\nTEST_RATIO = 0.1\\nSEED = 42\\nBUCKETS = 10\\n\\n# download an example dataset\\ndata = load_breast_cancer()\\ndf = pd.DataFrame(data[\\\"data\\\"], columns=data[\\\"feature_names\\\"])\\n\\n# create an 'index' column to use to uniquely identify each row\\ndf = df.reset_index(drop=False)\\n\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "import farmhash\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# set parameters\n",
    "TEST_RATIO = 0.1\n",
    "SEED = 42\n",
    "BUCKETS = 10\n",
    "\n",
    "# download an example dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "\n",
    "# create an 'index' column to use to uniquely identify each row\n",
    "df = df.reset_index(drop=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428a7b7",
   "metadata": {},
   "source": [
    "**Sklearn `train_test_split` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faea099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import train_test_split\\n\\n# split into training and test using a random seed\\nx_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\\n\\n# shuffle the orginal dataframe\\ndf_shuffled = df.sample(frac=1)\\n\\n# split the shuffled dataframe using the same random seed\\nx_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\\n    df_shuffled, test_size=TEST_RATIO, random_state=SEED\\n)\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import train_test_split\\n\\n# split into training and test using a random seed\\nx_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\\n\\n# shuffle the orginal dataframe\\ndf_shuffled = df.sample(frac=1)\\n\\n# split the shuffled dataframe using the same random seed\\nx_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\\n    df_shuffled, test_size=TEST_RATIO, random_state=SEED\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into training and test using a random seed\n",
    "x_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)\n",
    "\n",
    "# shuffle the orginal dataframe\n",
    "df_shuffled = df.sample(frac=1)\n",
    "\n",
    "# split the shuffled dataframe using the same random seed\n",
    "x_train_skl_shuffled, x_test_skl_shuffled = train_test_split(\n",
    "    df_shuffled, test_size=TEST_RATIO, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b363d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7866f65e",
   "metadata": {},
   "source": [
    "Let's compare the test sets using the row index which uniquely identifies each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417c3104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# compare the row ids included in each test set\\nset(x_test_skl[\\\"index\\\"]) == set(x_test_skl_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_formatted_code = \"# compare the row ids included in each test set\\nset(x_test_skl[\\\"index\\\"]) == set(x_test_skl_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the row ids included in each test set\n",
    "set(x_test_skl[\"index\"]) == set(x_test_skl_shuffled[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49173c6c",
   "metadata": {},
   "source": [
    "The rows included in each test set are not the same. Even though we set the random seed to be the same.\n",
    "\n",
    "This highlights how the sklearn `train_test_split` is sensitive to changes and ordering of the data.\n",
    "\n",
    "If you can't guarantee the order of the data will be the same each time, or if you are retraining on a dataset which contains the original data plus some new data, your data splits will be different even if you set the random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c4fd4",
   "metadata": {},
   "source": [
    "**Hashing method**\n",
    "\n",
    "For the hashing method we will need to create our own functions.\n",
    "\n",
    "We need to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe15218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def hash_value(value: Any) -> int:\\n    \\\"\\\"\\\"convert a value into a hashed value\\\"\\\"\\\"\\n    return farmhash.fingerprint64(str(value))\\n\\n\\ndef convert_hash_to_bucket(hashed_value: int, total_buckets: int) -> int:\\n    \\\"\\\"\\\"assign a bucket based off the hash value\\\"\\\"\\\"\\n    return abs(hashed_value % total_buckets)\\n\\n\\ndef test_set_check(bucket: int):\\n    \\\"\\\"\\\"check if the bucket should be included in the test set\\\"\\\"\\\"\\n    return bucket < TEST_RATIO * BUCKETS\\n\\n\\ndef assign_hash_bucket(value: Any) -> int:\\n    \\\"\\\"\\\"assign a bucket to an input value using hashing algorithm\\\"\\\"\\\"\\n    hashed_value = hash_value(value)\\n    bucket = convert_hash_to_bucket(hashed_value, total_buckets=BUCKETS)\\n    return bucket\\n\\n\\ndef hash_train_test_split(\\n    df: pd.DataFrame, split_col: str, approx_test_ratio: float\\n) -> tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"Split the data into a training and test set based of a specific column\\n\\n    Args:\\n        df (pd.DataFrame): original dataset\\n        split_col (str): name of the column to use for hashing algo\\n        approx_test_ratio (float): between 0-1. This is an approximate ratio\\n           as the hashing algo will not necessarily provide a uniform bucket\\n           distribution\\n\\n    Returns:\\n        tuple: Two dataframes, first is the training set and second is the\\n           test set\\n    \\\"\\\"\\\"\\n    df[\\\"buckets\\\"] = df[split_col].apply(assign_hash_bucket)\\n    in_test_set = df[\\\"buckets\\\"].apply(test_set_check)\\n    return df[~in_test_set], df[in_test_set]\";\n",
       "                var nbb_formatted_code = \"def hash_value(value: Any) -> int:\\n    \\\"\\\"\\\"convert a value into a hashed value\\\"\\\"\\\"\\n    return farmhash.fingerprint64(str(value))\\n\\n\\ndef convert_hash_to_bucket(hashed_value: int, total_buckets: int) -> int:\\n    \\\"\\\"\\\"assign a bucket based off the hash value\\\"\\\"\\\"\\n    return abs(hashed_value % total_buckets)\\n\\n\\ndef test_set_check(bucket: int):\\n    \\\"\\\"\\\"check if the bucket should be included in the test set\\\"\\\"\\\"\\n    return bucket < TEST_RATIO * BUCKETS\\n\\n\\ndef assign_hash_bucket(value: Any) -> int:\\n    \\\"\\\"\\\"assign a bucket to an input value using hashing algorithm\\\"\\\"\\\"\\n    hashed_value = hash_value(value)\\n    bucket = convert_hash_to_bucket(hashed_value, total_buckets=BUCKETS)\\n    return bucket\\n\\n\\ndef hash_train_test_split(\\n    df: pd.DataFrame, split_col: str, approx_test_ratio: float\\n) -> tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"Split the data into a training and test set based of a specific column\\n\\n    Args:\\n        df (pd.DataFrame): original dataset\\n        split_col (str): name of the column to use for hashing algo\\n        approx_test_ratio (float): between 0-1. This is an approximate ratio\\n           as the hashing algo will not necessarily provide a uniform bucket\\n           distribution\\n\\n    Returns:\\n        tuple: Two dataframes, first is the training set and second is the\\n           test set\\n    \\\"\\\"\\\"\\n    df[\\\"buckets\\\"] = df[split_col].apply(assign_hash_bucket)\\n    in_test_set = df[\\\"buckets\\\"].apply(test_set_check)\\n    return df[~in_test_set], df[in_test_set]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hash_value(value: Any) -> int:\n",
    "    \"\"\"convert a value into a hashed value\"\"\"\n",
    "    return farmhash.fingerprint64(str(value))\n",
    "\n",
    "\n",
    "def convert_hash_to_bucket(hashed_value: int, total_buckets: int) -> int:\n",
    "    \"\"\"assign a bucket based off the hash value\"\"\"\n",
    "    return abs(hashed_value % total_buckets)\n",
    "\n",
    "\n",
    "def test_set_check(bucket: int):\n",
    "    \"\"\"check if the bucket should be included in the test set\"\"\"\n",
    "    return bucket < TEST_RATIO * BUCKETS\n",
    "\n",
    "\n",
    "def assign_hash_bucket(value: Any) -> int:\n",
    "    \"\"\"assign a bucket to an input value using hashing algorithm\"\"\"\n",
    "    hashed_value = hash_value(value)\n",
    "    bucket = convert_hash_to_bucket(hashed_value, total_buckets=BUCKETS)\n",
    "    return bucket\n",
    "\n",
    "\n",
    "def hash_train_test_split(\n",
    "    df: pd.DataFrame, split_col: str, approx_test_ratio: float\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split the data into a training and test set based of a specific column\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): original dataset\n",
    "        split_col (str): name of the column to use for hashing algo\n",
    "        approx_test_ratio (float): between 0-1. This is an approximate ratio\n",
    "           as the hashing algo will not necessarily provide a uniform bucket\n",
    "           distribution\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two dataframes, first is the training set and second is the\n",
    "           test set\n",
    "    \"\"\"\n",
    "    df[\"buckets\"] = df[split_col].apply(assign_hash_bucket)\n",
    "    in_test_set = df[\"buckets\"].apply(test_set_check)\n",
    "    return df[~in_test_set], df[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7352f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# create a training and test set from original dataset using hashing method\\nx_train_hash, x_test_hash = hash_train_test_split(\\n    df, split_col=\\\"index\\\", approx_test_ratio=TEST_RATIO\\n)\\n\\n\\n# create a training and test set from shuffled dataset using hashing method\\nx_train_hash, x_test_hash_shuffled = hash_train_test_split(\\n    df_shuffled, split_col=\\\"index\\\", approx_test_ratio=TEST_RATIO\\n)\";\n",
       "                var nbb_formatted_code = \"# create a training and test set from original dataset using hashing method\\nx_train_hash, x_test_hash = hash_train_test_split(\\n    df, split_col=\\\"index\\\", approx_test_ratio=TEST_RATIO\\n)\\n\\n\\n# create a training and test set from shuffled dataset using hashing method\\nx_train_hash, x_test_hash_shuffled = hash_train_test_split(\\n    df_shuffled, split_col=\\\"index\\\", approx_test_ratio=TEST_RATIO\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a training and test set from original dataset using hashing method\n",
    "x_train_hash, x_test_hash = hash_train_test_split(\n",
    "    df, split_col=\"index\", approx_test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "\n",
    "# create a training and test set from shuffled dataset using hashing method\n",
    "x_train_hash, x_test_hash_shuffled = hash_train_test_split(\n",
    "    df_shuffled, split_col=\"index\", approx_test_ratio=TEST_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b1f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# compare the row ids included in each test set\\nset(x_test_hash[\\\"index\\\"]) == set(x_test_hash_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_formatted_code = \"# compare the row ids included in each test set\\nset(x_test_hash[\\\"index\\\"]) == set(x_test_hash_shuffled[\\\"index\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the row ids included in each test set\n",
    "set(x_test_hash[\"index\"]) == set(x_test_hash_shuffled[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f81211",
   "metadata": {},
   "source": [
    "Problem solved! Even though the underlying dataframe has been shuffled, the same row ids appear in the test dataset regardless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8cd45",
   "metadata": {},
   "source": [
    "Note, however, with the hashing method your data will not necessarily be split exactly by the ratio you specify. The larger your dataset, the less of an issue this will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b3951dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 46)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"total_records = len(df)\\ntarget_records = int(total_records * TEST_RATIO)\\nhash_test_set_records = len(x_test_hash)\\n\\ntarget_records, hash_test_set_records\";\n",
       "                var nbb_formatted_code = \"total_records = len(df)\\ntarget_records = int(total_records * TEST_RATIO)\\nhash_test_set_records = len(x_test_hash)\\n\\ntarget_records, hash_test_set_records\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_records = len(df)\n",
    "target_records = int(total_records * TEST_RATIO)\n",
    "hash_test_set_records = len(x_test_hash)\n",
    "\n",
    "target_records, hash_test_set_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77201c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"values = [farmhash.fingerprint64(str(i)) % 10 for i in range(1_000_000_0)]\\nsns.histplot(\\n    data=values,\\n    color=\\\"skyblue\\\",\\n    binwidth=1,\\n)\";\n",
       "                var nbb_formatted_code = \"values = [farmhash.fingerprint64(str(i)) % 10 for i in range(1_000_000_0)]\\nsns.histplot(\\n    data=values,\\n    color=\\\"skyblue\\\",\\n    binwidth=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [farmhash.fingerprint64(str(i)) % 10 for i in range(1_000_000_0)]\n",
    "sns.histplot(\n",
    "    data=values,\n",
    "    color=\"skyblue\",\n",
    "    binwidth=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447d0a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 1001297,\n",
       "         9: 998108,\n",
       "         1: 998962,\n",
       "         3: 1000155,\n",
       "         7: 999531,\n",
       "         8: 999567,\n",
       "         2: 1000679,\n",
       "         6: 1000185,\n",
       "         0: 1000657,\n",
       "         4: 1000859})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"from collections import Counter\\n\\nCounter(values)\";\n",
       "                var nbb_formatted_code = \"from collections import Counter\\n\\nCounter(values)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958b81e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"import farmhash\\n\\n\\ndir(farmhash)\\n\\nabs(farmhash.fingerprint64(\\\"abc\\\") % 10)\";\n",
       "                var nbb_formatted_code = \"import farmhash\\n\\n\\ndir(farmhash)\\n\\nabs(farmhash.fingerprint64(\\\"abc\\\") % 10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import farmhash\n",
    "\n",
    "dir(farmhash)\n",
    "\n",
    "abs(farmhash.fingerprint64(\"abc\") % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ded10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\n\\nn = np.uint64(farmhash.fingerprint64(\\\"1footrue\\\")).astype(\\\"int64\\\")\\nn % 10\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\n\\nn = np.uint64(farmhash.fingerprint64(\\\"1footrue\\\")).astype(\\\"int64\\\")\\nn % 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = np.uint64(farmhash.fingerprint64(\"1footrue\")).astype(\"int64\")\n",
    "n % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b5c719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def c_mod(a, b):\\n    res = a % b\\n    if a < 0:\\n        res -= b\\n    return res\\n\\n\\nc_mod(n, 10)\";\n",
       "                var nbb_formatted_code = \"def c_mod(a, b):\\n    res = a % b\\n    if a < 0:\\n        res -= b\\n    return res\\n\\n\\nc_mod(n, 10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def c_mod(a, b):\n",
    "    res = a % b\n",
    "    if a < 0:\n",
    "        res -= b\n",
    "    return res\n",
    "\n",
    "\n",
    "c_mod(n, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20592d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"abs(c_mod(-1541654101129638711, 10))\";\n",
       "                var nbb_formatted_code = \"abs(c_mod(-1541654101129638711, 10))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abs(c_mod(-1541654101129638711, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f6e94a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"abs(-1541654101129638711) % 10\";\n",
       "                var nbb_formatted_code = \"abs(-1541654101129638711) % 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abs(-1541654101129638711) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e59ab80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"s = -1541654101129638711\\nabs(s % 10)\";\n",
       "                var nbb_formatted_code = \"s = -1541654101129638711\\nabs(s % 10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = -1541654101129638711\n",
    "abs(s % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0cd715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"t = np.uint64(farmhash.fingerprint64(\\\"1footrue\\\")).astype(\\\"int64\\\")\\nabs(t % 10)\";\n",
       "                var nbb_formatted_code = \"t = np.uint64(farmhash.fingerprint64(\\\"1footrue\\\")).astype(\\\"int64\\\")\\nabs(t % 10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.uint64(farmhash.fingerprint64(\"1footrue\")).astype(\"int64\")\n",
    "abs(t % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a15373b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"-11 % 10\";\n",
       "                var nbb_formatted_code = \"-11 % 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-11 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d5b8f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"-1541654101129638711 % 10\";\n",
       "                var nbb_formatted_code = \"-1541654101129638711 % 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-1541654101129638711 % 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a831e9",
   "metadata": {},
   "source": [
    "SHOW MORE INFO ON HOW THE BUCKET DISTRIBUTIONS HAPPEN - E.G. HISTOGRAM PLOTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386d0cb",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "https://towardsdatascience.com/advanced-random-sampling-in-bigquery-sql-7d4483b580bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa60f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
